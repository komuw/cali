# Parsing

### 1. Parser
They take input(tokens, strings etc) and produce AST.  
  
  
```javascript
> var input = '{"name": "Thorsten", "age": 28}';
> var output = JSON.parse(input);
> output
{ name: 'Thorsten', age: 28 }
```
The above is a JS json parser taking string as input and producing a datastructure representing the input.  
The `abstract` in AST is based on the fact that certain details visible in the source code are omitted in the AST eg semicolons, newlines, whitespace etc  

Parsers take source code as input (either as text or tokens) and produce a data structure which represents this source code.  
While creating that data structure, they also analyse the input, checking that it conforms to the expected structure.   
Thus the process of parsing is also called `syntactic analysis`. That is where you get the famous; `parseError`  

We'll create a parser for cali, it's input will be the tokens produced by the [lexer](2.Lexing.md)  
We'll also define our own AST, suited to cali.  

### 2. Parser generators
These are tools that, when fed with a formal description of a language, produce
parsers as their output.  
Examples are; yacc, bison or ANTLR.  
The majority use a context-free grammar (CFG) as their input. Examples of CFGs are the
Backus-Naur Form (BNF) or the Extended Backus-Naur Form (EBNF).  
Parsers are well suited to being automatically generated, and you should use a parser generator if you can.  
We wont use a parser generator, however.

### 3. cali parser
There are 2 main parsing techniques top-down parsing or bottom-up parsing(with various variations in there.)   
The parser we are going to write is a recursive descent parser. And in particular, it’s a "top
down operator precedence" parser, sometimes called "Pratt parser".

### 3.1 Parsing let statements(and return statements)
```bash
let x = 5;
let foobar = add(5, 5);
```
We need to parse(produce AST) for `let` statements. They are of the form;
```bash
let <identifier> = <expression>;
```
where identifier and expression can change.  
Statement do not produce values, expresssions produce values: (this differs from one lang to the other)
`let x=5` doesnt produce value, `5` does. `return 5` is a statement, `add(5,5)` is an expression.  

We thus need two types of Nodes; a `Statement node` and an `Expression node`

```bash
let x = 5; 
```
can be represented by an AST like;
```bash
					*ast.Program
					Statements
						|
					*ast.LetStatement   
                         *ast.Identifier <-  Name
					     Value --> *ast.Expression
```  

The basic idea behind a `recursive descent parser` is(implemented in pseudocode);
```bash
function parseProgram() {
    program = newProgramASTNode()
    advanceTokens()

	for (currentToken() != EOF_TOKEN) {
		statement = null

		if (currentToken() == LET_TOKEN) {
		    statement = parseLetStatement()
		} else if (currentToken() == RETURN_TOKEN) {
		    statement = parseReturnStatement()
		} else if (currentToken() == IF_TOKEN) {
		    statement = parseIfStatement()
		}

		if (statement != null) {
		    program.Statements.push(statement)
		}

		advanceTokens()
	}

	return program
}

function parseLetStatement() {
	advanceTokens()
	identifier = parseIdentifier()
	advanceTokens()

	if currentToken() != EQUAL_TOKEN {
	    parseError("no equal sign!")
	    return null
	}
	advanceTokens()

	value = parseExpression()
	variableStatement = newVariableStatementASTNode()
	variableStatement.identifier = identifier
	variableStatement.value = value

	return variableStatement
}
```
and so on.   

parseProgram():
1. constructs the root node of the AST, an *ast.Program  
2. It iterates over every token in input until an token.EOF by repeatedly calling nextToken()  
   nextToken() advances both p.curToken and p.peekToken  
3. In every iteration it calls parseStatement, whose job it is to parse a statement.   
If parseStatement returned something(not nil), its return value is added to Statements slice   
4. When nothing is left to parse the *ast.Program root node is returned.    

parseLetStatement():  
1. constructs an *ast.LetStatement node with the current token(token.LET)  
2. advances the tokens while making assertions about the next token with calls to expectPeek.    
  - First it expects a token.IDENT, which it then uses to construct an *ast.Identifier node    
  - Then it expects an equal sign and finally it SKIPS over the expression following the equal sign until it encounters a semicolon.   
  The skipping of expressions will be replaced, of course, as soon as we know how to parse expressions.  

expectPeek() method is one of the `assertion funcs` that all parsers have.  
They enforce the correctness of the order of tokens by checking the type of the next token.  
Only if the type is correct does it advance the tokens by calling nextToken.  
If type is not correct, create a ParseError.  

parseReturnStatement() is similar to parseLetStatement()  
  

### 3.1 Parsing Expressions  
Parsing statements is easy; process tokens from left-to-right, accept or reject the next tokens and if everything fits we return an AST node.  
Expressions have some challenges, eg;
- operator precedence
	```
	5 * 5 + 10 == ((5 * 5) + 10)
	ie `*` should have higher precendence
	````
- expresssion tokens of same type can appear in multiple positions
	```
	- 5 - 10
	```
as compared to statements where u cant have `let x let = 5`  

In cali everything else besides `let` & `return` are expressions;
```
-5
!true
5 / 5
foo > bar
foo * bar / foobar
add(foo, bar)
fn(x, y) { return x + y }(5, 5)
etc
```

We will use the ideas presented in The paper "Top Down Operator Precedence" - by Vaughan Pratt to 
achieve our goal.  
prefix operator - is in front of operands `--5`  
postfix operator - is after operands `5++`  
infix operator - is in between operands `5 * 5`  

We add a third statement(besides `let` & `return`) to cali; `ExpressionStatement` 
```
let x = 5;
x + 10; //ExpressionStatement 
```
the second line is an `ExpressionStatement`  
`ExpressionStatement` is not really a distinct statement; it’s a
statement that consists solely of one expression.

A Pratt parser’s main idea is the association of parsing funcs with token types.  
Each token type can have up to two parsing funcs associated with it, depending on whether the
token is found in a prefix or an infix position.  
These parsingFuncs return `ast.Expression`

parseExpressionStatement() parses expressions by calling parseExpression.  
parseExpression() checks whether we have a parsing function associated with p.curToken.Type in the prefix position.
If we do, it calls this parsing function, else returns nil.  
For token.IDENT(identifier is like `myName` in `let myName = hi`) for example we define a prefixFunc called p.parseIdentifier.  
p.parseIdentifier() returns an `ast.Expression` (like all the prefix/infinix parsing funcs)  which is equal to;  
`&ast.Identifier{Token: p.curToken, Value: p.curToken.Value}`  

We also start work on `operator precendence` but we are yet to integrate it into parsing properly.  
