# LEXING

### 1. Lexical analysis
```bash
                   lexing/tokenization/scanning                  parsing
                   (lexer/tokenizer/scannner)                    (parser)
Source-code       ------------------------------>   Tokens   ---------------> AST 
"let x = 5 + 5;"                                    [
                                                    LET,
                                                    IDENTIFIER("x"),
                                                    EQUAL_SIGN,
                                                    INTEGER(5),
                                                    PLUS_SIGN,
                                                    INTEGER(5),
                                                    SEMICOLON
                                                    ]
```
what exactly constitutes a "token" varies between different lexer implementations.
A production-ready lexer might also attach the line number, column number and filename to
a token. A reason may be so that we can output useful error messages in the parsing stage:
```
"error: expected semicolon token. line 42, column 23, program.khaled"
```

### 2. Define tokens
```bash
let five = 5; #1. numbers like 5
let add = fn(x, y) { #2. keywords like fn, let
x + y; #3. vars like x, y, add, result
};
let result = add(five, ten); #4. special chars like (, ), {, }, ;
```

TokenType is a string. But using an int or byte would have better performance

### 3. Lexer
It will take source code as input and output the tokens that rep the source code.          
- We look at the current character under examination (l.ch) and return a token depending on which character it is.          
- Before returning the token we advance our pointers into the input          
  so when we call NextToken() again the l.ch field is already updated          
- isLetter().          
  Our lexer needs to recognize whether the current character is a letter and if so,                     
  it needs to read the rest of the identifier/keyword until it encounters a non-letter-character.          
- In khaled we treat _ as a letter and allow it in identifiers and keywords.          
  That means we can have var names like foo_bar. If you want to allow other chars in ua lang; add them here.          
- if we encounter a letter; read until we encounter a non letter(ie read whole word)          
  eg if we encounter- let - then we need to read whole of it(let) as one token          
- readChar gives us the next character and advance our position in the input string.          
  Our lexer only supports ASCII characters instead of full Unicode. This lets us keep things simple.           
  To support Unicode/UTF-8 we would need to change l.ch from a byte to rune and change the way we read the           
  next characters, since they could be multiple bytes wide now. Using l.input[l.readPosition]wouldn’t work anymore          
- skipWhitespace()          
  It eats whitespace. khaled doesnt require it unlike python.          
  This func is found in a lot of parsers. Sometimes it’s called eatWhitespace/consumeWhitespace.          
  Which chars these functions actually skip depends on the language being lexed.          
- We only read intergers. What about floats,hex notation, Octal notation?          
  We ignore em and say khaled doesn't support them.          
- peekChar()          
  We want to support tokens like == and !=          
  We can just add a new case in the switch statement inside NextToken() because          
  We can’t compare our l.ch byte with strings like "==" ie in Go "==" is a string whereas l.ch is a byte          
  What we can do instead is to reuse the existing branches for '=' and '!' and extend them.          
  So wel'll look ahead in the input and then determine whether to return a token for = or == etc          
            
  peekChar() is similar to readChar(), except that it doesn’t increment l.position and l.readPosition.          
  We only want to peek/look ahead in the input and not move around in it, so we know what a call to readChar() would return.          
  Most lexers/parser have such a peek function that looks ahead and most of the time it only returns the immediately next character.          
  Some even look behind, and some u have to look ahead/behind for more than one char.          
  
  An example of a lookAhead func in a real lexer/parser: https://github.com/Shopify/liquid/pull/235/files#diff-1b4fb3f28c5e976e2074edc03f6cb16cR41          


